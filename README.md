# Project: Lora-Trainer Forge

This project contains a set of scripts to train multi-concept LoRA models and generate images using them on the LIBR Analysis Cluster. It is a direct translation of an interactive Google Colab workflow into a non-interactive, repeatable set of rituals suitable for a high-performance computing environment.

---

### The Armory Layout

This is the domain you command. Understand its structure.

```text

Lora-Trainer/
├── kohya-trainer/      \# The sd-scripts repo. A necessary evil.
├── lora\_env/           \# Your forged sanctuary of tools. Generated by the setup script.
├── master\_dataset/     \# The souls of your subjects (training images).
│   └── 20\_character\_name/
├── scripts/            \# The incantations themselves.
│   ├── train\_lora.py
│   └── use\_lora.py
├── logs/               \# The echoes of your rituals (output logs from SLURM).
├── setup\_forge.sh      \# The script to build the sanctuary. Run this first, and only once.
├── submit\_training.ssub
├── submit\_inference.ssub
└── pose\_map.png        \# Your optional, but superior, map for the command ritual.

```

The primary output (trained models and final images) is not stored here. It is banished to the `/media/labs/mferguson/Lora-Trainer/` directory to preserve the meager space in your home directory.

---

### The Order of Operations

Follow these steps precisely. Deviation is for fools and those with power to waste. You are neither.

#### Step 0: The Offering (Prerequisites)

Before you begin any ritual, you must prepare the offerings.

1.  **Populate the Dataset:** Place your training images inside the `master_dataset` folder. Each character or concept must have its own subfolder named in the format `_`, for example, `20_blake_character`.
2.  **Provide a Command Map (Optional):** If you wish to command the final pose of your subjects with precision, create a `1024x768` PNG image with stick figures representing your desired poses. Name it `pose_map.png` and place it in the project root. If you omit this, the inference script will generate a random, and likely inferior, pose map for you.

#### Step 1: Forging the Sanctuary (Environment Setup)

Your tools must be sharp. This ritual forges the `lora_env` Python environment.

-   From the `~/Lora-Trainer/` directory, execute the setup script. You only need to perform this ritual **once**.
    ```bash
    ./setup_forge.sh
    ```

#### Step 2: The Ritual of Training

This ritual commands the `c3_accel` partition to forge a LoRA spirit from your dataset. This is a lengthy process.

-   Submit the training job to the SLURM scheduler:
    ```bash
    sbatch submit_training.ssub
    ```
-   Monitor its progress with `squeue -u $USER`.
-   Your trained `.safetensors` models will appear in `/media/labs/mferguson/Lora-Trainer/Multi_Concept_Output/`.

#### Step 3: The Ritual of Command

Once a spirit has been successfully forged (i.e., at least one `.safetensors` file exists), you may command it to create a vision.

-   Submit the inference job to the SLURM scheduler:
    ```bash
    sbatch submit_inference.ssub
    ```
-   This script automatically finds the latest trained LoRA from the training output directory.
-   The final masterpiece will be sealed at `/media/labs/mferguson/Lora-Trainer/Final_Images/final_command_scene.png`.

---

### Tuning the Instruments

If you wish to alter the rituals, these are the strings to pull:

-   **Storage Location:** The `LAB_STORAGE_ROOT` variable in both `scripts/train_lora.py` and `scripts/use_lora.py` can be changed if you decide to move your armory.
-   **Training Parameters:** All parameters for training (learning rate, resolution, epochs, etc.) are defined at the top of the `scripts/train_lora.py` file.
-   **Inference Prompt:** The prompt for the final image is defined within `scripts/use_lora.py`.
-   **Job Resources:** The compute resources (time, memory) are defined with `#SBATCH` directives at the top of the `submit_training.ssub` and `submit_inference.ssub` files.
