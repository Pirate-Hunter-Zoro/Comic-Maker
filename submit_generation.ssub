#!/bin/bash
#SBATCH --partition=c3_accel
#SBATCH --job-name=lora_inference
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2
#SBATCH --mem=32000
#SBATCH --gpus=1
#SBATCH --time=7-00:00:00
#SBATCH --output=logs/inference-%J.stdout
#SBATCH --error=logs/inference-%J.stderr

# --- The Command is Given ---
echo "A vision is being commanded on $(hostname)."
echo "Job ID: ${SLURM_JOB_ID}"
# Create the log directory if it doesn't exist.
mkdir -p ~/Visual-Novel-Writer/logs

# Load the necessary powers from the system.
module load Python/3.11.5-GCCcore-13.2.0
module load CUDA/12.3.0

# Enter your sanctuary.
source ~/Visual-Novel-Writer/lora_env/bin/activate

# Navigate to the root of your domain.
cd ~/Visual-Novel-Writer

# Unleash the inference incantation.
echo "Executing use_lora.py..."
python3 test_scripts/use_lora.py

echo "The vision has been made manifest."